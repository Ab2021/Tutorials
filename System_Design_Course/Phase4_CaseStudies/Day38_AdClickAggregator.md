# Day 38: Design Ad Click Aggregator

## 1. Requirements
*   **Functional:** Track clicks on ads. Aggregate metrics (Clicks per Ad, Clicks per User).
*   **Non-Functional:** Real-time reporting, Exact counting (Money involved), High throughput.
*   **Scale:** 1 Billion clicks/day.

## 2. Architecture
*   **Client:** Browser/App.
*   **Ad Server:** Logs click event to Kafka.
*   **Stream Processor (Flink):** Reads Kafka. Aggregates data.
*   **Storage:**
    *   **Raw:** HDFS/S3 (for audit).
    *   **Aggregated:** Druid / Pinot / ClickHouse (OLAP).
*   **Query Service:** Dashboard reads from OLAP DB.

## 3. Data Flow
1.  User clicks Ad `123`.
2.  Request: `POST /click?ad_id=123&user_id=456`.
3.  Server writes to Kafka Topic `ad_clicks`.
4.  Flink Window (1 min): `Count(ad_id)`.
5.  Flink writes result `(ad_id, timestamp, count)` to Druid.

## 4. Exactly-Once Semantics
*   **Critical:** If we double count, advertisers pay double. (Fraud).
*   **Idempotency:** Use `ClickID` (UUID) generated by client.
*   **Deduplication:** Flink stores `ClickID` in state (RocksDB) for 1 hour. Discard duplicates.
