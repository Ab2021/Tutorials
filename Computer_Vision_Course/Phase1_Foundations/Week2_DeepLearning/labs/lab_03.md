# Lab 03: Activation Functions

## Difficulty
ðŸŸ¢ Easy

## Estimated Time
30 mins

## Learning Objectives
- Non-linearity

## Problem Statement
Implement Sigmoid, Tanh, and ReLU functions and their derivatives.

## Starter Code
```python
def sigmoid(x):
    pass
```

## Hints
<details>
<summary>Hint 1</summary>
Focus on the core logic first.
</details>

## Solution
<details>
<summary>Click to reveal solution</summary>
Solution will be provided after you attempt the problem.
</details>
