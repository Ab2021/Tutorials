# Day 2, Topic 2: The Tool Use Pattern

The Tool Use pattern is another essential design pattern for building capable AI agents. It addresses a fundamental limitation of Large Language Models (LLMs): they are closed systems. An LLM's knowledge is limited to the data it was trained on, and it has no direct way to interact with the outside world.

The Tool Use pattern solves this problem by giving the agent access to a set of **tools**. A tool is simply a function or an API that the agent can call to perform a specific task.

## Why LLMs Alone Are Not Enough

There are several reasons why an agent needs tools to be effective:

*   **The Knowledge Cutoff Problem:** LLMs have a "knowledge cutoff" date. They do not have access to information about events that have happened since they were trained. For example, an LLM trained in 2022 would not know the winner of the 2023 World Cup.
*   **Access to Private or Proprietary Information:** An agent might need to access information that is not publicly available, such as a company's internal product database or a user's personal calendar.
*   **Performing Precise Calculations:** LLMs are notoriously bad at precise mathematical calculations. A calculator tool is much more reliable for this kind of task.
*   **Taking Action in the World:** An agent might need to take action in the real world, such as sending an email, booking a flight, or controlling a smart home device. This requires tools that can interact with the relevant APIs.

## Types of Tools

An agent's tools can be anything that can be called as a function. Some common types of tools include:

*   **Search Engines:** A tool that allows the agent to search the web for up-to-date information.
*   **Calculators:** A tool for performing mathematical calculations.
*   **Code Interpreters:** A tool that allows the agent to write and execute code in a sandboxed environment. This is very powerful for solving complex problems.
*   **Custom APIs:** You can create custom tools that allow the agent to interact with any API you want. This could be an internal company API, a third-party service, or your own custom application.

## How Agents Decide Which Tool to Use

The process of an agent deciding to use a tool typically involves the following steps:

1.  **Reasoning:** The agent's reasoning component (the LLM) determines that it needs to use a tool to complete a task.
2.  **Tool Selection:** The LLM decides which tool is the most appropriate for the task at hand. This is often done by providing the LLM with a list of available tools and their descriptions.
3.  **Input Formulation:** The LLM determines the necessary inputs for the selected tool.
4.  **Tool Call:** The agent's orchestration logic parses the LLM's output, identifies the tool call request, and executes the corresponding function with the specified inputs.
5.  **Observation:** The output of the tool is returned to the agent, and the LLM observes the result to continue its reasoning process.

This process is often facilitated by **function calling APIs**, such as the one provided by OpenAI. These APIs allow you to declare a set of tools to the LLM, and the LLM will then generate a structured response indicating when it wants to call one of those tools.

## Tool Security and Sandboxing

Giving an AI agent the ability to execute code and interact with external systems is incredibly powerful, but it also comes with significant security risks. A malicious or buggy agent could potentially:

*   Execute harmful code on the host system.
*   Access sensitive data.
*   Abuse APIs to send spam or perform other malicious actions.

It is therefore crucial to implement robust security measures when building tool-using agents. Here are some best practices:

*   **Sandboxing:** Any code generated by an agent should be executed in a sandboxed environment. A sandbox is an isolated environment that restricts the code's access to the host system's resources. This can be achieved using technologies like Docker containers or virtual machines.
*   **Permission Management:** An agent should only be given the minimum set of permissions it needs to perform its tasks. For example, if an agent only needs to read from a database, it should not be given write access.
*   **Human-in-the-Loop:** For high-risk actions (e.g., deleting a file, sending an email to a large number of people), it is often a good idea to require human approval before the action is executed.
*   **API Rate Limiting and Monitoring:** If an agent is interacting with external APIs, it is important to implement rate limiting to prevent abuse and to monitor the agent's API usage for any suspicious activity.

By following these best practices, you can build powerful tool-using agents that are also safe and secure.


## Exercise

1.  **Design a tool for a specific purpose (e.g., a tool to get the current weather for a given city).**
2.  **Define the tool's input and output schema.**
    *   **Tool Name:** `get_weather`
    *   **Description:** "Gets the current weather for a specified city."
    *   **Input Schema:**
        *   `city` (string, required): The name of the city.
    *   **Output Schema:**
        *   `temperature` (number): The current temperature in Celsius.
        *   `conditions` (string): A brief description of the weather conditions (e.g., "Sunny," "Cloudy," "Rain").
3.  **(Optional) Write a Python function that implements this tool.**
    *   *You can use a free weather API to get the data, or you can just return some hardcoded dummy data for the purpose of the exercise.*
