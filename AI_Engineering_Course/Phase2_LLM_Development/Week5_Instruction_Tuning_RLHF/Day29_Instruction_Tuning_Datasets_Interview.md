# Day 29: Instruction Tuning Datasets
## Interview Questions & Production Challenges

### Interview Questions

#### Q1: Why does LIMA (1k examples) outperform Alpaca (52k examples)?

**Answer:**
- **Quality over Quantity:** LIMA's 1k examples are meticulously curated by experts. Each example is diverse, challenging, and high-quality.
- **Alpaca's Noise:** Alpaca is synthetic (generated by GPT-3.5). It contains repetitive patterns, "GPT-isms" (overly apologetic tone), and factual errors.
- **Alignment Tax:** Training on too much low-quality data can degrade the model's pre-trained knowledge (Catastrophic Forgetting).

#### Q2: What is "Self-Instruct" and how does it work?

**Answer:**
- **Concept:** Use an LLM (GPT-3.5/4) to generate synthetic instruction-response pairs.
- **Process:** Start with a few seed examples. Prompt the LLM to generate new instructions that are different from the seeds. Use the LLM again to generate responses for those instructions.
- **Benefit:** Cheap, scalable. Can generate 50k examples for $500.
- **Drawback:** Synthetic data has biases and lacks diversity compared to real user queries.

#### Q3: Explain "Evol-Instruct". How is it different from Self-Instruct?

**Answer:**
- **Self-Instruct:** Generates new instructions from scratch (breadth).
- **Evol-Instruct:** Takes existing instructions and makes them progressively more complex (depth).
- **Example:** "List fruits" → "List 10 exotic fruits with health benefits" → "Compare 10 exotic fruits by antioxidant levels, cite studies."
- **Result:** Creates harder, more reasoning-intensive instructions that improve model capability.

#### Q4: What is "Data Contamination" in the context of instruction tuning?

**Answer:**
- **Problem:** If your training data contains questions from the test set (e.g., MMLU, HumanEval), your evaluation is invalid. The model has "seen the answers" during training.
- **Detection:** Check n-gram overlap or embedding similarity between training data and benchmark test sets.
- **Solution:** Deduplicate against all known benchmarks before training.

#### Q5: How do you measure the quality of an instruction dataset?

**Answer:**
- **Diversity:** Topic coverage, instruction type variety (QA, Summarization, Reasoning).
- **Complexity:** Average sentence length, verb diversity, reasoning steps required.
- **Accuracy:** Factual correctness of responses (NLI check, human eval).
- **Safety:** Toxicity score, PII presence.

---

### Production Challenges

#### Challenge 1: ShareGPT Contains PII

**Scenario:** You downloaded ShareGPT. It contains user emails, phone numbers, and private info.
**Solution:**
- **Regex Scrubbing:** Remove patterns matching emails, phones, SSNs.
- **NER (Named Entity Recognition):** Use a model (spaCy) to detect and redact PERSON, ORG, LOC entities.
- **Manual Review:** Sample 1000 random examples and manually check for leaks.

#### Challenge 2: Synthetic Data is Too Uniform

**Scenario:** You generated 50k instructions with GPT-3.5. The model trained on it sounds robotic.
**Root Cause:** GPT-3.5 has a specific "voice" (polite, verbose, uses "Certainly!"). The model learns this style instead of being natural.
**Solution:**
- **Mix Real Data:** 50% Synthetic + 50% Real (ShareGPT, Reddit).
- **Prompt Diversity:** Use different system prompts when generating ("Be concise", "Be casual", "Be technical").
- **Post-Processing:** Remove filler phrases ("Certainly!", "I'd be happy to").

#### Challenge 3: Instruction Length Imbalance

**Scenario:** 90% of your instructions are short ("What is X?"), 10% are long (multi-step reasoning).
**Result:** The model becomes bad at complex tasks.
**Solution:**
- **Stratified Sampling:** Ensure balanced representation of short/medium/long instructions.
- **Evol-Instruct:** Evolve the short instructions to make them longer and more complex.

#### Challenge 4: Evaluating Instruction Diversity

**Scenario:** You have 100k instructions. How do you know if they are diverse?
**Solution:**
- **Embedding Clustering:** Embed all instructions using Sentence-BERT. Cluster them (K-Means, k=100). Check cluster sizes. If one cluster has 50k samples, it's not diverse.
- **Topic Modeling:** Use LDA or BERTopic to extract topics. Ensure coverage across domains (Code, Math, Chat, Creative Writing).

### Summary Checklist for Production
- [ ] **Source:** Mix **50% Synthetic / 50% Real**.
- [ ] **Dedup:** Remove duplicates and contamination.
- [ ] **Clean:** Scrub **PII** and **Toxicity**.
- [ ] **Evolve:** Use **Evol-Instruct** for complexity.
- [ ] **Eval:** Measure **Diversity** (clustering).
