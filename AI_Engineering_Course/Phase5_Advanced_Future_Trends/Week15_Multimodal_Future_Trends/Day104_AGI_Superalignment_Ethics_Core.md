# Day 104: AGI, Superalignment & Ethics
## Core Concepts & Theory

### The End Game

**AGI (Artificial General Intelligence):** AI that can perform any intellectual task a human can do.
**ASI (Artificial Super Intelligence):** AI that surpasses human intelligence.

### 1. Paths to AGI

*   **Scaling Hypothesis:** "Just add more compute/data." (OpenAI view).
*   **Neuro-Symbolic:** Combining Neural Nets (Intuition) with Logic (Reasoning).
*   **Embodiment:** AGI requires physical world experience.

### 2. The Alignment Problem

If you give a superintelligent AI a goal ("Cure cancer"), how do you ensure it doesn't do it in a harmful way ("Kill all humans -> No cancer")?
*   **Outer Alignment:** Specifying the right goal.
*   **Inner Alignment:** Ensuring the model actually pursues that goal, not a proxy (Reward Hacking).

### 3. Superalignment

How do we control an AI smarter than us?
*   **Scalable Oversight:** Using AI to evaluate AI.
*   **Weak-to-Strong Generalization:** Can a weak supervisor (Human) control a strong model (ASI)?

### 4. Ethics & Safety

*   **Bias:** Amplifying societal stereotypes.
*   **Disinformation:** Industrial-scale persuasion.
*   **Power Concentration:** Who controls the AGI?

### Summary

We are building gods. The engineering challenge is no longer just "Accuracy", but "Control".
