# PyTorch & Deep Learning Course

> **Goal**: Master Deep Learning with PyTorch, from Tensors to Transformers and Generative AI.
> **Structure**: 40 Days of intensive learning.
> **Format**: Each day includes:
> 1.  **Core Concept**: Theory and Implementation.
> 2.  **Deep Dive (`_part1`)**: Advanced internals, edge cases, and optimization.
> 3.  **Interview Prep (`_interview`)**: 20 Questions with detailed answers.

## Phase 1: PyTorch Foundations (Days 1-10)
### Week 1: The Engine
*   **Day 1**: Tensors & Memory Management (Strides, Storage, GPU)
*   **Day 2**: Autograd & Computational Graphs (Jacobians, Backprop)
*   **Day 3**: Optimization & Loss Landscapes (SGD, Adam, Convexity)
*   **Day 4**: Neural Network Architecture (`nn.Module`, Layers)
*   **Day 5**: The Training Loop (Boilerplate to Best Practices)

### Week 2: Data & Workflow
*   **Day 6**: Data Engineering (Datasets, Dataloaders, Workers)
*   **Day 7**: Augmentation & Transforms (Invariance, Equivariance)
*   **Day 8**: Serialization & Checkpointing (State Dicts)
*   **Day 9**: Debugging & Visualization (Hooks, TensorBoard)
*   **Day 10**: PyTorch Lightning (Refactoring for Scale)

## Phase 2: Computer Vision (Days 11-20)
### Week 3: CNNs & Architectures
*   **Day 11**: Convolutions (Receptive Fields, Kernels)
*   **Day 12**: Modern Backbones (ResNet, EfficientNet, ConvNeXt)
*   **Day 13**: Transfer Learning strategies
*   **Day 14**: Object Detection (YOLO, R-CNN)
*   **Day 15**: Segmentation (U-Net, Mask R-CNN)

### Week 4: Generative & Deployment
*   **Day 16**: Autoencoders (Latent Manifolds)
*   **Day 17**: GANs (Nash Equilibrium, Mode Collapse)
*   **Day 18**: Video Understanding (3D CNNs, Time)
*   **Day 19**: Deployment (TorchScript, ONNX, TRT)
*   **Day 20**: Mobile Optimization (Quantization)

## Phase 3: NLP & Transformers (Days 21-30)
### Week 5: Sequences
*   **Day 21**: RNNs & LSTMs (BPTT, Vanishing Gradients)
*   **Day 22**: Embeddings (Vector Space, Word2Vec)
*   **Day 23**: Seq2Seq & Attention (Bahdanau)
*   **Day 24**: The Transformer (Self-Attention, Multi-Head)
*   **Day 25**: BERT & Encoders (Masked LM)

### Week 6: LLMs
*   **Day 26**: GPT & Decoders (Causal LM)
*   **Day 27**: Tokenization (BPE, SentencePiece)
*   **Day 28**: Hugging Face Ecosystem
*   **Day 29**: Efficient Fine-Tuning (LoRA, QLoRA)
*   **Day 30**: RLHF (PPO, DPO)

## Phase 4: Advanced Topics (Days 31-40)
### Week 7: Modern AI
*   **Day 31**: Diffusion Models (DDPM, Latent Diffusion)
*   **Day 32**: Graph Neural Networks (Message Passing)
*   **Day 33**: Distributed Training (DDP, FSDP)
*   **Day 34**: Custom CUDA Kernels (Triton)
*   **Day 35**: Profiling & Optimization

### Week 8: Systems & Capstone
*   **Day 36**: Vector Databases & RAG
*   **Day 37**: Multimodal Models (CLIP)
*   **Day 38**: Time Series (Transformers for Time)
*   **Day 39**: Recommender Systems
*   **Day 40**: Final Review & Career
